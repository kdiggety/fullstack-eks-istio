name: ci-ml

on:
  push:
    branches: [ main ]
    paths:
      - 'llm-gateway/**'
      - 'retriever/**'
      - 'anomaly-scorer/**'
      - 'helm/apps/chart-ml/**'
      - 'helm/modules/**'
      - 'k8s/ml-namespace.yaml'
      - '.github/workflows/ci-ml.yml'
  workflow_dispatch: {}

permissions:
  contents: read
  packages: write

concurrency:
  group: ci-ml-${{ github.ref }}
  cancel-in-progress: true

jobs:
  build:
    name: Build & Push Images
    runs-on: [self-hosted, local-k8s]
    timeout-minutes: 60
    strategy:
      matrix:
        svc: [ llm-gateway, retriever, anomaly-scorer ]

    env:
      OWNER: ${{ github.repository_owner }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      # QEMU + Buildx (same pattern as backend)
      - name: Setup QEMU (multi-arch)
        uses: docker/setup-qemu-action@v3

      - name: Setup Docker Buildx
        uses: docker/setup-buildx-action@v3
        with:
          install: true
          use: true
          driver: docker-container
          buildkitd-flags: --debug

      - name: Derive short tag
        id: meta
        shell: bash
        run: echo "SHORT=${GITHUB_SHA:0:7}" >> "$GITHUB_OUTPUT"

      - name: Login to GHCR
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.repository_owner }}
          password: ${{ secrets.GITHUB_TOKEN }}

      # Build contexts are root-level: ./llm-gateway, ./retriever, ./anomaly-scorer
      - name: Build & Push ${{ matrix.svc }} (multi-arch)
        id: build_push
        uses: docker/build-push-action@v6
        with:
          context: ./${{ matrix.svc }}
          push: true
          provenance: false
          platforms: linux/arm64,linux/amd64
          tags: |
            ghcr.io/${{ env.OWNER }}/${{ matrix.svc }}:${{ github.sha }}
            ghcr.io/${{ env.OWNER }}/${{ matrix.svc }}:${{ steps.meta.outputs.SHORT }}
            ghcr.io/${{ env.OWNER }}/${{ matrix.svc }}:dev
          cache-from: type=registry,ref=ghcr.io/${{ env.OWNER }}/${{ matrix.svc }}:buildcache
          cache-to: type=registry,ref=ghcr.io/${{ env.OWNER }}/${{ matrix.svc }}:buildcache,mode=max
          labels: |
            org.opencontainers.image.revision=${{ github.sha }}
            org.opencontainers.image.source=${{ github.repository }}

  deploy:
    name: Deploy AI/ML
    needs: build
    runs-on: [self-hosted, local-k8s]
    timeout-minutes: 30
    env:
      GHCR_USER: ${{ github.repository_owner }}
      GHCR_TOKEN: ${{ secrets.GHCR_TOKEN }}
    steps:
      - uses: actions/checkout@v4

      - uses: azure/setup-kubectl@v4
      - uses: azure/setup-helm@v4
        # with:
        #   version: v3.14.4  # (optional) ensure --set-json support (Helm >= 3.12)

      # Use the runner's local kube context (docker-desktop)
      - name: Use local kube context (docker-desktop)
        run: |
          set -euo pipefail
          unset KUBECONFIG
          kubectl config use-context docker-desktop
          kubectl cluster-info
          kubectl get nodes -o wide

      - name: Helm repos
        run: |
          helm repo add bitnami https://charts.bitnami.com/bitnami
          helm repo add argo https://argoproj.github.io/argo-helm
          helm repo update

      - name: Build Helm deps (apps/modules layout)
        run: |
          helm dependency build helm/modules/chart-minio
          helm dependency build helm/modules/chart-argo
          helm dependency build helm/apps/chart-ml

      - name: Ensure namespace
        run: kubectl apply -f k8s/ml-namespace.yaml

      - name: Ensure GHCR imagePullSecret on namespace SA
        if: ${{ env.GHCR_TOKEN != '' }}
        run: |
          kubectl -n ml create secret docker-registry ghcr-pull \
            --docker-server=ghcr.io \
            --docker-username="$GHCR_USER" \
            --docker-password="$GHCR_TOKEN" \
            --dry-run=client -o yaml | kubectl apply -f -
          kubectl -n ml patch serviceaccount default --type merge \
            -p '{"imagePullSecrets":[{"name":"ghcr-pull"}]}'

      - name: Helm upgrade/install (Local-only providers, no mesh OIDC/AuthZ)
        run: |
          helm upgrade --install ml helm/apps/chart-ml -n ml \
            --reset-values \
            --set meshMl.host="*" \
            --set meshMl.gateway="istio-system/web-gateway" \
            --set-json meshMl.oidc=null \
            --set-json meshMl.authz=null \
            \
            --set llm-gateway.image.repository="ghcr.io/${{ github.repository_owner }}/llm-gateway" \
            --set retriever.image.repository="ghcr.io/${{ github.repository_owner }}/retriever" \
            --set anomaly-scorer.image.repository="ghcr.io/${{ github.repository_owner }}/anomaly-scorer" \
            --set llm-gateway.image.tag="${{ github.sha }}" \
            --set retriever.image.tag="${{ github.sha }}" \
            --set anomaly-scorer.image.tag="${{ github.sha }}" \
            \
            # ---------- Local LLM via Ollama ----------
            --set llmGateway.provider.type=ollama \
            --set llmGateway.provider.baseUrl="http://ollama.ml.svc.cluster.local:11434" \
            --set llmGateway.provider.model="llama3.1:8b" \
            --set llmGateway.provider.disableAutoDetect=true \
            \
            # ---------- Local embeddings + reranker ----------
            --set retriever.embedder.provider=local \
            --set retriever.embedder.model="all-MiniLM-L6-v2" \
            --set reranker.provider=local \
            --set reranker.model="cross-encoder/ms-marco-MiniLM-L-6-v2" \
            \
            # Disable KServe models unless CRDs are installed
            --set kserveModels.enabled=false

